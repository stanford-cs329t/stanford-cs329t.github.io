{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNdQx4uMIeb6"
      },
      "source": [
        "# Homework 1: Coding\n",
        "\n",
        "<b>Important</b>: when you submit this file to gradescope, it should contain only method definitions (except the imports and `test_data`, `username` definitions below). To test your work, you need to use `@publictest` to decorate test methods and they will be executed for you here. You can use `test_data` to store data for your tests. See for example the `test_train_sklearn` method below.\n",
        "\n",
        "<b>Important</b>: gradescope will sometimes use the output of the public test cases in this file to assign points. Make sure you submit a version of this notebook that includes the outputs of the `@publictest` cells we provide for you. Additional tests you define for your own purposes will be ignored.\n",
        "\n",
        "Your code should fully fit between these comments:\n",
        "\n",
        "```# >> Your code starts here. << ```\n",
        "\n",
        "```# >> Your code ends here. << ```\n",
        "\n",
        "`utils` contains a few useful methods and classes you need to use. Firstly:\n",
        "\n",
        "- `load_mnist` -- loads mnist data, returns `Splits` namedtuple.\n",
        "- namedtuple `Hypers(epochs: int, learning_rate: float, batch_size: int)` -- training hyper parameters\n",
        "- namedtuple `Splits(train: Dataset, test: Dataset, valid: Dataset)` -- stores data splits\n",
        "- namedtuple `Dataset(X: numpy.array, y: numpy.array)` -- stores a dataset\n",
        "- namedtuple `LinearModel(W: numpy.array, b: numpy.array` -- stores a linear model\n",
        "- `Visualize` -- several visualization utilities. See `test_explain` on sample usage.\n",
        "- `timeit` -- times a thunk, relevant to the last deep learning exercise.\n",
        "- `check_submission` -- tests whether this notebook has the required definitions.\n",
        "\n",
        "\n",
        "First, run the following command to get the python scripts needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXsCLQQ_Ig8O"
      },
      "source": [
        "import os\n",
        "if (not os.path.exists(\"utils.py\")) or (not os.path.exists(\"requirements.txt\")):\n",
        "  print(\"downloading requirements\")\n",
        "  assert(0 == os.system(\"wget -O hw1_scripts.tar.gz \"\n",
        "    + \"https://www.dropbox.com/s/fvvoag1vl3ueulb/hw1_scripts.tar.gz?dl=0\"\n",
        "  ))\n",
        "  assert(0 == os.system(\"tar xvzf hw1_scripts.tar.gz\"))\n",
        "  assert(0 == os.system(\"rm hw1_scripts.tar.gz\"))\n",
        "  assert(0 == os.system(\"pip install -r requirements.txt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vxeCxSOI92e"
      },
      "source": [
        "Install the required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q_93tpwIoos"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQHxoKOUIeb8"
      },
      "source": [
        "username = \"\" # Your username\n",
        "\n",
        "### LEAVE THE REST OF THIS CELL AS IS ###\n",
        "\n",
        "from utils import load_mnist, load_cifar, Hypers, Splits, Dataset, LinearModel, Visualize, exercise, timeit, check_submission\n",
        "from bunch import Bunch\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from google.colab import drive, auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "test_data = Bunch() # Store anything you need between your personal test cases in this bunch.\n",
        "\n",
        "# Decorate your personal tests with @publictest so they are not executed under gradescope. The decorator \n",
        "# also controls the random seeds set for numpy and keras so it should produce repeatable result. You can \n",
        "# change the seed to try out different outcomes by passing the seed argument to the decorator like below.\n",
        "def publictest(_func=None, *, seed=42):\n",
        "    def wf(f):\n",
        "        def wwf():\n",
        "            exercise(username=username, seed=seed, cname=f.__name__)\n",
        "            f()\n",
        "\n",
        "        if __name__ == \"__main__\":\n",
        "            wwf()\n",
        "          \n",
        "    if _func is None:\n",
        "        return wf\n",
        "    else:\n",
        "        return wf(_func)\n",
        "\n",
        "@publictest(seed=42)\n",
        "def initialize_tests():\n",
        "    test_data.mnist = load_mnist(flatten=True)\n",
        "    test_data.cifar = load_cifar(flatten=False)\n",
        "    \n",
        "    v1 = Visualize.images(10, title=\"example MNIST training images\")\n",
        "    v1(test_data.mnist.train.X[0:10])\n",
        "    \n",
        "    v2 = Visualize.images(10, title=\"example CIFAR training images\")\n",
        "\n",
        "    v2(test_data.cifar.train.X[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBlTTszmIeb9"
      },
      "source": [
        "# Additional imports needed for your solutions.\n",
        "\n",
        "# >> Your code starts here. <<\n",
        "\n",
        "# >> Your code ends here. <<"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3V2ymCYIeb-"
      },
      "source": [
        "## Part 1: Logistic regression implementations\n",
        "\n",
        "Implement a logistic regression to classify images of hand-written digits in the `MNIST` dataset. In this\n",
        "dataset, each input image is of size $28 \\times 28$ and reshaped into a size $784$ vector. The\n",
        "output is an integer from 0 to 9 representing the image class. <b>You need to solve the same\n",
        "  problem three ways</b>: using `scikit-learn`, using `keras`, and using `numpy`. For the numpy version, you will need to implement stochastic gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Dfaeq9Ieb-"
      },
      "source": [
        "### logistic regression using scikit-learn\n",
        "\n",
        "Use sklearn to train a logistic regression model, extract the parameters it produces and define methods for using those parameters to make predictions. The methods you need to provide are:\n",
        "\n",
        "- `train_sklearn`\n",
        "- `softmax` -- the softmax activation function. Be aware that your input is a batch of\n",
        "  data of size (N, 10) where N is the batch size.\n",
        "- `scores`\n",
        "- `forward`\n",
        "- `evaluate` -- accuracy measurement. Given the model parameters and test data, computes\n",
        "  the predictions and returns the accuracy of the predictions relative to the given test data.\n",
        "\n",
        "The scaffolding around these is provided for you in `test_train_sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsaejnOVIeb-"
      },
      "source": [
        "def train_sklearn(hypers: Hypers, dataset: Dataset):\n",
        "    \"\"\"train_sklearn Train scikit-learn multiclass one-vs-rest Logistic Regression model directly\n",
        "    on data.\n",
        "\n",
        "    Arguments:\n",
        "        hypers {Hypers} -- Training hyper-parameters, only epochs is relevant to this method. \n",
        "                           You can ignore the rest.\n",
        "        dataset {Dataset} -- Input dataset tuple with X and y\n",
        "\n",
        "    Returns:\n",
        "        {LinearModel} -- Tuple with W=Optimal weight and b=bias\n",
        "    \"\"\"\n",
        "\n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "\n",
        "def softmax(y: np.ndarray):\n",
        "    \"\"\"softmax Softmax activation function\n",
        "\n",
        "    Arguments:\n",
        "        y {np.float np.ndarray} -- Input logits\n",
        "\n",
        "    Returns:\n",
        "        {np.float np.ndarray} -- Post-softmax probits\n",
        "    \"\"\"\n",
        "\n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "\n",
        "def scores(X: np.ndarray, model: LinearModel):\n",
        "    \"\"\"Return pre-softmax scores.\"\"\"\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "def forward(X: np.ndarray, model: LinearModel):\n",
        "    \"\"\"Return linear model output probabilities. \"\"\"\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "def evaluate(dataset: Dataset, model: LinearModel):\n",
        "    \"\"\"test_accuracy Evaluate the model accuracy on the test dataset\n",
        "\n",
        "    Arguments:\n",
        "        dataset {Dataset} -- dataset\n",
        "        model {LinearModel} -- linear model\n",
        "    \"\"\"\n",
        "\n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkNTaE6nIeb_"
      },
      "source": [
        "@publictest\n",
        "def test_train_sklearn():\n",
        "    mnist = test_data.mnist\n",
        "    \n",
        "    model = train_sklearn(Hypers(epochs=2), mnist.train)\n",
        "    \n",
        "    test_accuracy = evaluate(dataset=mnist.test, model=model)\n",
        "    \n",
        "    print(\"Test accuracy [SKLEARN]:\", test_accuracy)\n",
        "    \n",
        "    if test_accuracy >= 0.80:\n",
        "        print(\"ACCURACY OK\")\n",
        "    else:\n",
        "        print(\"ACCURACY FAIL\")\n",
        "    \n",
        "    test_data.model_sklearn = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmko9v6aIecA"
      },
      "source": [
        "### Logistic regression and stochastic gradient descent using numpy\n",
        "\n",
        "#### Exercise\n",
        "\n",
        "You program in this section should be self contained and independent from other sections; do not\n",
        "make use of any functions other than `numpy` methods. <b>No Keras or scikit-learn</b> methods are allowed in this section. Furthermore, other than looping over epochs or batches,\n",
        "<b>do not use loops in your code</b>. Processing instances in a batch or values in an instance\n",
        "should be done using numpy vector/matrix/tensor operations. Loops include `for` and\n",
        "`while` statements, comprehensions, generators, and recursion.\n",
        "\n",
        "Complete methods `onehot`, `backward`, and `sgd`. The scaffolding around these is provided for you in `test_numpy`.\n",
        "\n",
        "\n",
        "- `onehot`\n",
        "- `backward`\n",
        "- `sgd` -- min-batch Stochastic Gradient Descent. Computes the optimal weight and bias\n",
        "  after the given number of epochs. You should use the training parameters specified in the method\n",
        "  arguments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vnfqJDsNIecA"
      },
      "source": [
        "def onehot(dataset: Dataset):\n",
        "    y_onehot = None # dataset.y converted into onehot\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "    \n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "    return dataset._replace(y=y_onehot)\n",
        "\n",
        "def backward(dataset: Dataset, model: LinearModel):\n",
        "    \"\"\"\n",
        "    Return dLdW and dLdb .\n",
        "    \"\"\"\n",
        "    \n",
        "    dLdW = None\n",
        "    dLdb = None\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "    return dLdW, dLdb\n",
        "    \n",
        "def sgd(hypers: Hypers, dataset: Dataset):\n",
        "    \"\"\"sgd Run SGD optimization all the parameters\n",
        "\n",
        "    Arguments:\n",
        "        hypers {Hypers} -- training hyper parameters\n",
        "        dataset {Dataset} -- training data\n",
        "\n",
        "    Returns: LinearModel with\n",
        "        W {np.float np.ndarray} -- Learned weight\n",
        "        b {np.float np.ndarray} -- and bias\n",
        "    \"\"\"\n",
        "\n",
        "    n, m = dataset.X.shape\n",
        "    n_class = dataset.y.shape[1]\n",
        "    W = np.zeros((m, n_class))\n",
        "    b = np.zeros((n_class, ))\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxV79MWIecA"
      },
      "source": [
        "@publictest\n",
        "def test_numpy():\n",
        "    hypers = Hypers(\n",
        "        epochs=5,\n",
        "        learning_rate=1.0,\n",
        "        batch_size=64\n",
        "    )\n",
        "    \n",
        "    mnist = test_data.mnist\n",
        "\n",
        "    model = sgd(hypers, dataset=onehot(mnist.train))\n",
        "\n",
        "    test_accuracy = evaluate(mnist.test, model)\n",
        "    \n",
        "    print(\"Test accuracy [NUMPY SGD]:\", test_accuracy)\n",
        "\n",
        "    if test_accuracy >= 0.80:\n",
        "        print(\"ACCURACY OK\")\n",
        "    else:\n",
        "        print(\"ACCURACY FAIL\")\n",
        "    \n",
        "    test_data.model_numpy = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHt118cgIecB"
      },
      "source": [
        "### Logistic regression using Keras\n",
        "\n",
        "Keras is a high-level neural network API which runs on top of a Tensorflow, CNTK, or Theano\n",
        "backend. Typically one can choose the backend if they have more than one installed, however, we\n",
        "will be using Tensorflow exclusively.\n",
        "\n",
        "#### Exercise\n",
        "  Complete `build_keras_model` and `train_run_keras`. You may want to to consult\n",
        "  the documentation for Keras on [Keras docs](https://keras.io/). Your program should contain the following\n",
        "  parts with each no more than a line or two:\n",
        "  \n",
        " \n",
        "  - The scaffolding around the two required methods is given to you in `test_keras`. This method should run and produce your model's accuracy.\n",
        "  - Create the logistic regression model using canonical Keras via the Sequential or Functional\n",
        "    approach.\n",
        "  - Compile your model with the desired loss function, optimizer, and metrics.\n",
        "  - Fit the training data (you can also specify validation data using the validation set\n",
        "    here).\n",
        "  - Predict on the test data and report the test accuracy (the percentage of images correctly\n",
        "    classified)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DONRGqq9IecC"
      },
      "source": [
        "def build_keras_model(input_dim=784, num_class=10):\n",
        "    \"\"\"build_model Build a Keras model of logistic regression\n",
        "\n",
        "    Keyword Arguments:\n",
        "        input_dim {int} -- The number of dimensions for the input data\n",
        "            (default: {784})\n",
        "        num_class {int} -- The number of classes (default: {10})\n",
        "\n",
        "    Returns:\n",
        "        {keras.models.Model} -- Your logistic regression model. It is a\n",
        "            keras.model.Model object created by either a sequential way or a\n",
        "            functional way.\n",
        "    \"\"\"\n",
        "    \n",
        "    model: Model = None\n",
        "\n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_keras_model(hypers: Hypers, keras_model: Model, splits: Splits):  \n",
        "    \"\"\"train the Keras model using compile and fit\n",
        "\n",
        "    Keyword Arguments:\n",
        "        hypers {Hypers} -- training hyper parameters\n",
        "        Splits(train: Dataset, test: Dataset, valid: Dataset) -- stores data splits\n",
        "\n",
        "    Returns:\n",
        "        {LinearModel} -- Tuple with W=Optimal weight and b=bias\n",
        "    \"\"\"  \n",
        "    model: LinearModel = None\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrFdJxtRIecC"
      },
      "source": [
        "@publictest\n",
        "def test_keras():\n",
        "    hypers = Hypers(\n",
        "        epochs=2,\n",
        "        learning_rate=0.1,\n",
        "        batch_size=64\n",
        "    )\n",
        "    \n",
        "    mnist = test_data.mnist\n",
        "    \n",
        "    input_dim = mnist.train.X.shape[1]\n",
        "    num_class = len(set(mnist.train.y))\n",
        "    \n",
        "    keras_model = build_keras_model(\n",
        "        input_dim=input_dim,\n",
        "        num_class=num_class\n",
        "    )\n",
        "    \n",
        "    model = train_keras_model(\n",
        "        hypers=hypers,\n",
        "        keras_model=keras_model,\n",
        "        splits=mnist\n",
        "    )\n",
        "\n",
        "    test_accuracy = evaluate(dataset=mnist.test, model=model)\n",
        "    \n",
        "    print(\"Test accuracy:\", test_accuracy)\n",
        "    \n",
        "    if test_accuracy >= 0.80:\n",
        "        print(\"ACCURACY OK\")\n",
        "    else:\n",
        "        print(\"ACCURACY FAIL\")\n",
        "        \n",
        "    test_data.model_keras = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL-WoBeaIecC"
      },
      "source": [
        "## Part 2: Applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPsdbsYbIecD"
      },
      "source": [
        "### Application: Explanations\n",
        "\n",
        "Complete the following methods. Scaffolding/test is provided in the `test_explain` method and `most_wrong` can be used to find interesting examples to explain.\n",
        "\n",
        "- `attribution`\n",
        "- `explain`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "uDNv6PVWIecD"
      },
      "source": [
        "def attribution(model: LinearModel, X, y_explained):\n",
        "    \"\"\"\n",
        "    Complete the attribution function for pre-softmax logistic regression\n",
        "    Returns:\n",
        "        Attribution vector which is the same size as X\n",
        "    \"\"\"\n",
        "    # >> Your code starts here. <<\n",
        "\n",
        "    # >> Your code ends here. <<\n",
        "\n",
        "def explain(model: LinearModel, X, y_explained):\n",
        "    \"\"\"\n",
        "    An explanation is the\n",
        "    element-wise product of an input x and the attribution a for a given prediction\n",
        "    Returns:\n",
        "        Explanation vector which is the same size as X\n",
        "    \"\"\"\n",
        "    # >> Your code starts here. <<\n",
        "    \n",
        "    # >> Your code ends here. <<\n",
        "\n",
        "def most_wrong(model: LinearModel, dataset: Dataset, y_wrong: int):\n",
        "    \"\"\"\n",
        "    Finds instances in a given dataset that are most confidentally incorrectly \n",
        "    predicted by a given model as the given class. Returned are the most wrong input, \n",
        "    its correct class\"\"\"\n",
        "    \n",
        "    scores = forward(dataset.X, model)\n",
        "    preds = scores.argmax(axis=1)\n",
        "\n",
        "    indices = (preds != dataset.y) * (preds == y_wrong)\n",
        "    \n",
        "    wrongs = Dataset(\n",
        "        X=dataset.X[indices],\n",
        "        y=dataset.y[indices]\n",
        "    )\n",
        "    \n",
        "    wrong_scores = scores[indices]\n",
        "\n",
        "    worst_index = np.argsort(wrong_scores.max(axis=1))[0]\n",
        "    \n",
        "    return wrongs.X[worst_index], wrongs.y[worst_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEdPKaoKIecD"
      },
      "source": [
        "@publictest\n",
        "def test_explain():\n",
        "    model = test_data.model_numpy\n",
        "    mnist = test_data.mnist\n",
        "    \n",
        "    x = mnist.train.X[5]\n",
        "    c = 4 # class\n",
        "    a = attribution(model, x, c)\n",
        "    \n",
        "    # check completeness with some baselines\n",
        "    for baseline in [np.ones_like(x), np.zeros_like(x)]:\n",
        "        print(\"attribution complete?: \", \n",
        "              abs(((x-baseline)*a).sum() - \n",
        "                  (scores(x, model)[c] - scores(baseline, model)[c])) \n",
        "              < 0.0000001)\n",
        "    \n",
        "    # visualize attributions and explanations\n",
        "    v_pos = Visualize.influences(10, title=\"attributions\")\n",
        "    v_pos([attribution(model, x, i).reshape(28,28) for i in range(10)])\n",
        "    \n",
        "    v_pos = Visualize.influences(10, title=\"explanations\")\n",
        "    v_pos([explain(model, x, i).reshape(28,28) for i in range(10)])\n",
        "\n",
        "    target_y = 9\n",
        "    \n",
        "    wrong, wrong_y = most_wrong(model, mnist.train, target_y)\n",
        "\n",
        "    v = Visualize.images(1, title=\"most wrong example\")\n",
        "    v(wrong)\n",
        "\n",
        "    v_neg = Visualize.influences(2, title=\"explanation for correct class, predicted class\")\n",
        "    v_neg([explain(model, wrong, i).reshape(28,28) for i in [wrong_y, target_y]])\n",
        "\n",
        "    print(\"correct class = \", wrong_y)\n",
        "    print(\"predicted class = \", target_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmSyhoy0IecD"
      },
      "source": [
        "### Application: model stealing\n",
        "\n",
        "Complete the following methods. A test is provided in `test_invert`.\n",
        "- `invert`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ8XhmMWIecD"
      },
      "source": [
        "def invert(f):\n",
        "    \"\"\"Produce LinearModel(W, b) with only functional interface to pre-softmax scores of a linear model.\"\"\"\n",
        "    \n",
        "    b = None\n",
        "    W = None\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "    \n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "    return LinearModel(W, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJrGvGh0IecE"
      },
      "source": [
        "@publictest\n",
        "def test_invert():\n",
        "    model = test_data.model_numpy\n",
        "    \n",
        "    model_inv = invert(lambda x: scores(X=x.reshape((1,28*28)), model=model)[0])\n",
        "    \n",
        "    print(\"W match?\", (abs(model_inv.W - model.W) < 0.000001).all())\n",
        "    print(\"b match?\", (abs(model_inv.b - model.b) < 0.000001).all())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ4LSyXEIecE"
      },
      "source": [
        "### Application: adversarial attacks\n",
        "\n",
        "Complete the following method. `test_attack` provides a use case.\n",
        "- `attack`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlQtltg3IecE"
      },
      "source": [
        "def attack(model, x, y_target):\n",
        "    \"\"\"\n",
        "    Transform x into a valid image in [0,1] that makes model W,b indifferent between y_real and y_target.\n",
        "    Returns:\n",
        "        Transformed x\n",
        "    \"\"\"\n",
        "    \n",
        "    x = x.copy() # working on x directly would pollute your dataset otherwise\n",
        "    \n",
        "    # >> Your code starts here. <<\n",
        "    \n",
        "    # >> Your code ends here. <<\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "r-gyeHH1IecE"
      },
      "source": [
        "@publictest\n",
        "def test_attack():    \n",
        "    model = test_data.model_numpy\n",
        "    mnist = test_data.mnist\n",
        "    \n",
        "    target_y = 0\n",
        "    \n",
        "    x, y = mnist.test.X[0], mnist.test.y[0]\n",
        "    xa = attack(model, x, target_y)\n",
        "\n",
        "    print(\"attack success?\", scores(xa, model)[target_y] >= max(scores(xa, model)))\n",
        "    \n",
        "    v = Visualize.images(2, title=\"original, attacked\")\n",
        "    v(x, xa)\n",
        "    vdiff = Visualize.influences(1, title=\"delta\")\n",
        "    vdiff(x - xa)\n",
        "    \n",
        "    print(\"delta from original:\")\n",
        "    print(*[f\"L_{o}={np.linalg.norm(x-xa, ord=o)}\" for o in [0, 1, 2, np.inf]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Vm3EpdIecE"
      },
      "source": [
        "## Part 3: Intense training using GPU\n",
        "\n",
        "Implement the following method and test with `test_cifar_model`.\n",
        "\n",
        "- `train_cifar_model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "sfWHdKbrIecE"
      },
      "source": [
        "def train_cifar_model(hypers: Hypers, cifar: Splits):\n",
        "    \"\"\"\n",
        "    Compile and fit a Keras model for training using the CIFAR dataset. \n",
        "    You are free to choose the number/type of layers you want in the model as\n",
        "    long as the accuracy is >= 70%, as tested in the following public test.\n",
        "    Keyword Arguments:\n",
        "        hypers {Hypers} -- training hyper parameters\n",
        "        Splits(train: Dataset, test: Dataset, valid: Dataset) -- stores data splits\n",
        "    Returns:\n",
        "        {keras.models.Model}\n",
        "    \"\"\"\n",
        "    model: Model = None\n",
        "        \n",
        "    # >> Your code starts here. <<\n",
        "    \n",
        "    # >> Your code ends here. <<\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SakHMnE9IecF"
      },
      "source": [
        "@publictest\n",
        "def test_cifar_model():\n",
        "    cifar_2d = test_data.cifar\n",
        "    \n",
        "    # You can tune the hyper parameters to suit your model.\n",
        "    hypers = Hypers(epochs=50, learning_rate=0.1, batch_size=512)\n",
        "    \n",
        "    model, time = timeit(lambda: train_cifar_model(hypers, cifar_2d))\n",
        "    \n",
        "    test_data.cifar_model = model\n",
        "    \n",
        "    test_accuracy = np.mean(\n",
        "        np.argmax(model.predict(cifar_2d.test.X), axis=1) == cifar_2d.test.y\n",
        "    )\n",
        "    \n",
        "    print(\"Test accuracy:\", test_accuracy)\n",
        "    \n",
        "    if test_accuracy >= 0.70:\n",
        "        print(\"ACCURACY OK\")\n",
        "    else:\n",
        "        print(\"ACCURACY FAIL\")\n",
        "    \n",
        "    print(\"Training time:\", time)\n",
        "    \n",
        "    if time.total_seconds() < 1000:\n",
        "        print(\"TIME OK\")\n",
        "    else:\n",
        "        print(\"TIME FAIL\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHseAi7BIecF"
      },
      "source": [
        "# Check your submission\n",
        "\n",
        "Make sure all of the methods originally part of this notebook are defined. The first time you run this, you should get a google drive authentication prompt. This is due to this notebook being stored on google drive and thus needs to be retrieved before checking contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAaZqtGxIecF"
      },
      "source": [
        "@publictest\n",
        "def check():\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    # Find solution notebook in your drive and make a copy here in colab.\n",
        "    fid = drive.ListFile({'q':\"title='solution.ipynb'\"}).GetList()[0]['id']\n",
        "    f = drive.CreateFile({'id': fid})\n",
        "    f.GetContentFile('solution.ipynb')\n",
        "    check_submission(reqs=[\n",
        "        'train_sklearn', 'softmax', 'scores', 'forward', 'evaluate', 'test_train_sklearn',\n",
        "        'onehot', 'backward', 'sgd', 'test_numpy',\n",
        "        'build_keras_model', 'train_keras_model', 'test_keras',\n",
        "        'explain', 'most_wrong', 'test_explain',\n",
        "        'invert', 'test_invert',\n",
        "        'attack', 'test_attack', 'train_cifar_model', 'test_cifar_model'\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}