<!DOCTYPE html>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">

    <title>CS 329T | Syllabus</title>

    <!-- bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

    <!-- Google fonts -->
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body>
    <script src="header.js"></script>

    <div class="container sec" id="schedule" style="margin-top:-20px"><br>
        <h2><i class="far fa-calendar-alt"> </i> Schedule & syllabus</h2>
        <p>
            The lecture slides,abs, and assignments will be posted online here as the course progresses. All the pre-recorded lectures would be uploaded Monday every week on Canvas.<br>
            Lecture times are <b>2:30-3:50pm PST</b>. All deadlines are at <b>11:59pm PST</b>.
        </p>
        <p>
            <em>This schedule is subject to change according to the pace of the class.</em>
        </p>
        <table class="table">
            <thead>
                <tr class="active">
                    <th style="width: 10%">Date</th>
                    <th style="width: 32%">Description</th>
                    <th style="width: 38%">Materials</th>
                    <th style="width: 20%">Events</th>
                </tr>
            </thead>
            <tbody>
                <tr bgcolor="#dddddd">
                    <td></td>
                    <td></td>
                    <td>Part I: Background (Week 1) </td>
                    <td></td>
                </tr>

                <tr>
                    <td>Mon Mar 29</td>
                    <td>Week 1 Presentation topics: <br>
                        <ol>
                            Course overview<br>
                            Background: Deep learning<br>
                            Background: Vision <br>
                            Background: Keras <br>
                        </ol>

                    </td>
                    <td>
<!--                        TODO: Add links-->
                       Slides
                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue Mar 30</td>
                    <td>Orientation, overview Fireside chat, course QA and introduce final project
                    </td>
                    <td>
                        <a href="slides/part1-week1-video01-overview.pdf" target="_blank">Slides</a><br>
                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu Apr 1</td>
                    <td>Troubleshooting Homework 0 <br> Intro to Homework 1
                    </td>
                    <td>
                        <a href="slides/CS329T_Lab1.pdf" target="_blank">Slides</a>
                    </td>
                    <td>Lab<br><br>Homework 1 <font color="green">Released:</font><br>
                        [<a href="homeworks/hw1/CS329T_HW1.pdf" target="_blank">pdf</a>]<br>
                        [<a href="homeworks/hw1/CS329T_HW1_Code.zip">Code</a>]<br>
                        [<a href="homeworks/hw1/CS329T_HW1_Written.zip">Written Template</a>]
                        <br><br>
                    Description: Homework 1 is designed to make sure you are comfortable with ML fundamentals that will be needed in this course.
                    If you are struggling with parts of this assignment, consider whether you meet the prerequisites. <br><br>
                    Learning outcomes: Background checkpoint <br><br>
                    Content: XGboost, Python, Sci-kit learn, Tensorflow for vision


                    </td>
                </tr>


                <tr bgcolor="#dddddd">
                    <td></td>
                    <td></td>
                    <td>Part II: Explanations (Weeks 2 and 3) </td>
                    <td></td>
                </tr>

                <tr>
                    <td>Mon Apr 5</td>
                    <td>Week 2 Presentation topics: <br>
                        <ol>
                            Explanations overview<br>
                            Local explanations<br>
                            Input importance and Shapley values
                        </ol>
                    </td>
                    <td>
                        <a href="https://finale.seas.harvard.edu/files/finale/files/an_evaluation_of_the_human-interpretability_of_explanation.pdf">An Evaluation of the Human-Interpretability of Explanation</a><br>
                        <a href="https://dl.acm.org/doi/pdf/10.1145/2939672.2939778">Why Should I Trust You?": Explaining the Predictions of Any Classifier</a><br>
                        <a href="https://arxiv.org/pdf/1703.01365.pdf">Axiomatic Attribution for Deep Networks</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue Apr 6</td>
                    <td>Shapley values in explanations: SHAP & QII

                    </td>
                    <td>
                        <a href="slides/part1-week2-video01-explanations.pdf" target="_blank">Slides</a><br>
                        <a href="https://www.andrew.cmu.edu/user/danupam/datta-sen-zick-oakland16.pdf">Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems</a><br>
                        <a href="https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf">A Unified Approach to Interpreting Model Predictions</a><


                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu Apr 8</td>
                    <td>Intro to Homework 2 <br>
                    
                    </td>
                    
                    <td>
                        <a href="slides/CS329T_Lab2.pdf" target="_blank">Slides</a>
                    </td>
                    <td>Lab</td>
                </tr>
                <tr>
                    <td>Fri Apr 9</td>
                    <td>Homework 1 due</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Sat Apr 10</td>
                    <td>Homework 2</td>
                    <td></td>
                     <td>Homework 2 <font color="green">Released:</font><br>
                        [<a href="homeworks/hw2/CS329T_HW2.pdf" target="_blank">pdf</a>]<br>
                        [<a href="homeworks/hw2/CS329T_HW2_Code.zip">Code</a>]<br>
                        [<a href="homeworks/hw2/CS329T_HW2_Written.zip">Written Template</a>]
                        <br><br>
                </tr>
                <tr>
                    <td>Mon Apr 12</td>
                    <td>Week 3 Presentation topics: <br>
                        <ol>
                            Vision attributions (saliency maps, integrated gradients, layerwise relevant propagation, etc.) <br>
                            Evaluations for attributions<br>
                            Training point influence
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="https://arxiv.org/pdf/2002.07985.pdf">Interpreting Interpretations: Organizing Attribution Methods by Criteria</a><br>
                        <a href="https://papers.nips.cc/paper/2018/file/8a7129b8f3edd95b7d969dfc2c8e9d9d-Paper.pdf">Representer point selection for DNN</a><br>
                        <a href="https://arxiv.org/pdf/1703.04730.pdf">Understanding Black-box Predictions via Influence Functions</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue Apr 13</td>
                    <td>More deep learning introspection methods
                    </td>

                    <td>
                        <a href="slides/explanations-Week2.pdf" target="_blank">Slides</a><br><br>
                        <a href="https://arxiv.org/pdf/1902.03129.pdf">Towards Automatic Concept-based Explanations</a><br>
                        <a href="https://arxiv.org/abs/1802.03788">Influence-Directed Explanations for CNNs</a>

                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu Apr 15</td>
                    <td>Homework 2 Q/A <br>
                    </td>
                    <td>
                        <a href="slides/CS329T_Lab3.pdf" target="_blank">Slides</a>
                    </td>
                    <td>Lab
                </tr>
                <tr bgcolor="#dddddd">
                    <td></td>
                    <td></td>
                    <td>Part III: Fairness (Weeks 4 and 5) </td>
                    <td></td>
                </tr>

                <tr>
                    <td>Mon Apr 19</td>
                    <td>Week 4 Presentation topics: <br>
                        <ol>
                            Fairness overview<br>
                            Mitigation in Data<br>
                            Individual Fairness
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="https://pdfs.semanticscholar.org/1d17/4f0e3c391368d0f3384a144a6c7487f2a143.pdf?_ga=2.198712170.499045504.1611253703-113508275.1611253703">Big Data's Disparate Impact</a><br>
                        <a href="https://arxiv.org/pdf/1412.3756v3.pdf">Certifying and Eliminating Disparate Impact</a><br>
                        <a href="http://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf">Fairness through Awareness</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue Apr 20</td>
                    <td>
                        <ol>
                            How fair do we need to be? Disparate impact/connections to legal sector<br>
                            Problems with measuring fairness in the real world<br>
                        </ol>
                    </td>

                    <td>
                        Slides<br>
                        <a href="https://arxiv.org/abs/1412.3756">Certifying and removing disparate impact</a><br>
                        <a href="https://arxiv.org/pdf/1808.00023.pdf">The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning</a>
                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu Apr 22</td>
                    <td>Intro to Homework 3 <br>TBD
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>

                 <tr>
                    <td>Mon Apr 26</td>
                    <td>Week 5 Presentation topics: <br>
                        <ol>
                            Mitigation with Adversarial Learning<br>
                            Bias in NLP: Embeddings<br>
                            Bias in NLP: Beyond embeddings
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="https://arxiv.org/abs/1801.07593">Mitigation with Adversarial Learning</a><br>
                        <a href="http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf">Man is to Computer Programmer as Woman is to Homemaker?</a><br>
                        <a href="https://arxiv.org/abs/1807.11714">Gender Bias in Neural Natural Language Processing</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue Apr 27</td>
                    <td>
                        Ethical implications, bias in non-language settings<br>
                    </td>

                    <td>
                        Slides<br>
                        <a href="http://opus.bath.ac.uk/55288/4/CaliskanEtAl_authors_full.pdf">Human-like Bias in Language Models</a><br>
                        <a href="https://arxiv.org/ftp/arxiv/papers/2010/2010.07023.pdf">Understanding bias in facial recognition technologies</a>
                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu Apr 29</td>
                    <td>Homework 3 Q/A <br>TBD
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>

                <tr bgcolor="#dddddd">
                    <td></td>
                    <td></td>
                    <td>Part IV: Privacy (Weeks 6 and 7) </td>
                    <td></td>
                </tr>

                <tr>
                    <td>Mon May 3</td>
                    <td>Week 6 Presentation topics: <br>
                        <ol>
                            Privacy overview<br>
                            Membership inference<br>
                            Model inversion
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="http://arxiv.org/pdf/1705.07807.pdf">Use Privacy in Data-Driven Systems: Theory and Experiments with Machine Learnt Programs</a><br>
                        <a href="https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2017.pdf">Membership Inference Attacks Against Machine Learning Models</a><br>
                        <a href="https://dl.acm.org/doi/pdf/10.1145/2810103.2813677">Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue May 4</td>
                    <td>
                        White-box vs Black-box: Bayes Optimal Strategies for Membership Inference
                    </td>

                    <td>
                        Slides<br>
                        <a href="http://proceedings.mlr.press/v97/sablayrolles19a/sablayrolles19a.pdf">White-box vs Black-box: Bayes Optimal Strategies for Membership Inference</a><br>

                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu May 6</td>
                    <td>Intro to Homework 4 <br>TBD
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>

                 <tr>
                    <td>Mon May 10</td>
                    <td>Week 7 Presentation topics: <br>
                        <ol>
                            Location privacy<br>
                            Federated learning<br>
                            Privacy and Explanations
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="https://core.ac.uk/download/pdf/9713419.pdf">Quantifying Location Privacy</a><br>
                        <a href="https://arxiv.org/pdf/1812.00910">Comprehensive Privacy Analysis of Deep Learning: Stand-alone and Federated Learning under Passive and Active White-box Inference Attacks</a><br>
                        <a href="https://arxiv.org/pdf/1907.00164.pdf">On the Privacy Risks of Model Explanations</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue May 11</td>
                    <td>
                        <ol>
                            Differential Privacy: A Survey of Results<br>
                            No Free Lunch in Data Privacy
                        </ol>
                    </td>

                    <td>
                        Slides<br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-540-79228-4_1">Differential Privacy: A Survey of Results</a><br>
                        <a href="http://www.cse.psu.edu/~duk17/papers/nflprivacy.pdf">No Free Lunch in Data Privacy</a>
                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu May 13</td>
                    <td>Homework 4 Q/A <br>TBD
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>


                <tr bgcolor="#dddddd">
                    <td></td>
                    <td></td>
                    <td>Part V: Robustness (Weeks 8 and 9) </td>
                    <td></td>
                </tr>

                <tr>
                    <td>Mon May 17</td>
                    <td>Week 8 Presentation topics: <br>
                        <ol>
                            Robustness overview<br>
                            Adversarial attacks<br>
                            Real-world adversarial attacks
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="https://arxiv.org/pdf/1511.07528.pdf">The Limitations of DL in Adversarial Settings</a><br>
                        <a href="https://arxiv.org/pdf/1608.04644">Towards Evaluating the Robustness of Neural Networks</a><br>
                        <a href="https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf">DReal and Stealthy Attacks on State-of-the-Art Face Recognition</a>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue May 18</td>
                    <td>
                        <ol>
                            Adversarial Examples Are Not Bugs, They Are Features <br>
                            How does adversarial robustness play a role in model explainability (to be discussed further in next week’s Presentation topics)?
                        </ol>
                    </td>

                    <td>
                        Slides<br>
                        <a href="https://arxiv.org/pdf/1905.02175.pdf">Adversarial Examples Are Not Bugs, They Are Features</a><br>

                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu May 20</td>
                    <td>Intro to Homework 5 <br>Implement basic attacks for small models
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>

                 <tr>
                    <td>Mon May 24 </td>
                    <td>Week 9 Presentation topics: <br>
                        <ol>
                            Adversarial defenses <br>
                            Attacks on attributions<br>
                            Defenses against attacks on attributions<br>
                        </ol>
                    </td>
                    <td>
<!--                        TODO: Add links-->
                        Slides<br>
                        <a href="https://arxiv.org/pdf/1706.06083.pdf">Towards Deep Learning Models Resistant to Adversarial Attacks</a><br>
                        <a href="https://arxiv.org/pdf/1710.10547.pdf">Explanations can be manipulated and geometry is to blame</a><br>
                        <a href="https://arxiv.org/abs/1711.09404">Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients</a><br>

                    </td>
                    <td>Pre-recorded lecture</td>
                </tr>

                <tr>
                    <td>Tue May 25</td>
                    <td>
                        <ol>
                            How to certify robustness? <br>
                            Fast Geometric Projections for Local Robustness Certification<br>
                            Non-deep net adversarial attacks on explanations?<br>
                            Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods
                        </ol>
                    </td>

                    <td>
                        Slides<br>
                        <a href="https://arxiv.org/abs/2002.04742">Fast Geometric Projections for Local Robustness Certification</a><br>
                        <a href="https://arxiv.org/abs/1911.02508">Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods</a>
                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>

                <tr>
                    <td>Thu May 27</td>
                    <td>Homework 5 Q/A <br>TBD
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>

                <tr bgcolor="#dddddd">
                    <td></td>
                    <td></td>
                    <td>Part VI: Synthesis and Takeaways (Week 10) </td>
                    <td></td>
                </tr>


                <tr>
                    <td>Tue Jun 1</td>
                    <td>
                        Final assignment presentations
                    </td>

                    <td>
                    </td>
                    <td>Fireside chat Lecture</td>
                </tr>
                <tr>
                    <td>Thu Jun 3</td>
                    <td>Final assignment presentations
                    </td>
                    <td>
                        Slides
                    </td>
                    <td>Lab
                </tr>
            </tbody>
        </table>
    </div>



    <!-- jQuery and Boostrap -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
</body>


</html>
